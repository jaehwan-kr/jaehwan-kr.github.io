---
layout: single
title:  "LLM을 넘어 행동하는 AI로: AI Agent에 대해서"
categories: study
tag: [AI, AI agent, Artificial Intelligence, Tech Trend]
typora-root-url: ../
toc: true
toc_sticky: true
toc_label: 목차
author_profile: false

---


<hr>
### 들어가며: LLM의 한계와 AI 에이전트의 등장
<div style="font-size: 18px;" markdown="1">
평소 챗GPT나 제미나이 같은 LLM(Large Language Model)을 자주 사용하시나요? 이들은 방대한 지식을 갖춘 아주 똑똑한 '조언자'입니다. 하지만 이들에게는 명확한 한계가 있습니다. 바로 현실 세계의 일을 직접 처리해주지는 못한다는 점입니다.

예를 들어, LLM은 완벽한 여행 계획표를 1초 만에 짜줄 수는 있어도, 실제로 항공사 사이트에 접속해 티켓을 예매해주지는 못합니다. 기존 LLM은 사용자의 질문에 답변만 생성하는 **'수동적'**인 구조이기 때문입니다. 스스로 계획을 세우거나, 외부 시스템과 연결되어 실질적인 업무를 수행하기에는 구조적인 어려움이 있습니다.

이러한 한계를 극복하고, 단순히 '말만 하는 AI'에서 나를 대신해 **'행동하는 AI'**로 나아가는 개념이 바로 **AI 에이전트(AI Agent)**입니다.
</div>

<hr>

### 1. AI 에이전트(AI Agent)란?

<div style="font-size: 18px;" markdown="1">
구글에서는 AI 에이전트를 다음과 같이 정의합니다.

> AI 에이전트는 AI를 사용해 사용자를 대신하여 목표를 추구하고 태스크를 완료하는 소프트웨어 시스템입니다. AI 에이전트는 추론, 계획, 기억이 가능하며 일정 수준의 자율성을 갖고 의사 결정, 학습, 조정을 처리합니다.
</div>

<hr>

### 2. AI 에이전트의 구조
<div style="font-size: 18px;" markdown="1">
AI 에이전트는 크게 세 가지 요소로 구성됩니다.
</div>

![ai-agent-1](/images/2026-01-19-ai-agent/ai-agent-1.png)

<div style="font-size: 18px;" markdown="1">

- <span style="font-size: 22px;" markdown="1"> **모델 (Model)** - 두뇌 </span><br>
에이전트의 핵심 의사결정자입니다. 상황을 파악하고 사용자의 의도를 분석합니다.   
주로 LLM이나 특정 작업에 최적화된 SLM(Small Language Model)이 사용됩니다.

- <span style="font-size: 22px;" markdown="1"> **도구 (Tools)** - 팔과 다리 </span><br>
실제 작업을 수행하기 위해 AI가 활용하는 다양한 기능들의 집합체로서, 모델이 현실 세계와 상호작용하기 위한 수단입니다.   
외부 데이터 및 서비스 정보와 상호작용할 수 있게 되어 모델의 기능을 확장합니다.

- <span style="font-size: 22px;" markdown="1"> **오케스트레이션 (Orchestration)** - 신경망 </span><br>
목표 달성을 위해 모델과 도구의 순서를 조율하는 레이어입니다.   
**'정보 인식 → 내부 추론 → 행동 실행 → 피드백'**의 순환 과정(Cyclical process)을 목표가 달성될 때까지 반복합니다.

</div>

<hr>

### 3. 작동 원리: 문제 해결 4단계
<div style="font-size: 18px;" markdown="1">
AI 에이전트는 복잡한 문제를 해결할 때 일반적으로 다음 4단계를 거칩니다.

- 목표 (Goal): 사용자의 모호한 명령에서 정확한 의도와 목표를 파악합니다.

- 인식 (Perception): 센서나 데이터를 통해 현재의 디지털/물리적 환경 정보를 수집합니다.

- 추론 (Reasoning): 목표와 환경 정보를 바탕으로 어떤 도구를 쓸지, 어떤 순서로 행동할지 계획을 세웁니다.

- 행동 (Action): 실제 API를 호출하거나 로봇을 움직여 작업을 수행합니다.
</div>

<hr>

### 4. 주요 활용 사례
<div style="font-size: 18px;" markdown="1">
이미 AI 에이전트는 우리 곁에 다가와 있습니다.<br>

- <span style="font-size: 22px;" markdown="1"> **아마존의 알렉사+(Alexa+)** </span><br>   
![ai-agent-3](/images/2026-01-19-ai-agent/ai-agent-3.png)<br>

알렉사+는 생성형 AI 기술을 적극 활용한 차세대 음성 비서로, 대화형 AI 에이전트의 가능성을 보여주는 대표적인 사례입니다.   
알렉사+의 기능으로는 개인화된 서비스와 선제적 제안, 생산성 향상을 위한 고급 기능, 보안 기능과 스마트 카메라 연동, 통합된 스마트 홈 제어 시스템 등이 있습니다.   
예를 들면, 이메일이나 파일을 분석하여 중요한 정보를 요약하거나, 음성 명령만으로 레스토랑 예약을 진행하는 등 복잡한 작업도 처리할 수 있습니다. 

- <span style="font-size: 22px;" markdown="1"> **앤트로픽의 컴퓨터 유즈** </span><br>
![ai-agent-4](/images/2026-01-19-ai-agent/ai-agent-4.png)<br>

컴퓨터 유즈는 키보드 입력, 버튼 클릭, 마우스 커서 이동 등 컴퓨터 조작에 필요한 모든 작업을 마치 사람처럼 수행할 수 있습니다. 클로드라는 최신 AI 모델에 기반한 컴퓨터 유즈는 실제 사용자 컴퓨터의 다양한 소프트웨어와 시스템에 접근하고, 사용자 명령을 이해하며 복잡한 작업을 실행할 능력을 갖추고 있습니다. 이를 바탕으로 문서 작성, 인터넷 검색, 스프레드시트 작업뿐만 아니라 프로그램 설치와 같은 작업까지도 스스로 할 수 있는 소프트웨어입니다. 
</div>

<hr>

### 5. 한계점
<div style="font-size: 18px;" markdown="1">
물론 완벽하지는 않습니다. 에이전트 기술이 직면한 과제들은 다음과 같습니다.

- **데이터 의존성**: 학습 데이터가 부족하거나 편향되면 잘못된 의사결정을 내릴 수 있습니다.

- **무한 루프**: 해결책을 찾지 못하고 계속 같은 행동만 반복하는 현상이 발생할 수 있습니다.

- **보안 취약성**: 가장 치명적인 단점입니다.   
AI 에이전트가 실제로 실행까지 하려면, 내부의 다양한 시스템들과 연동이 필요합니다. 하지만 이 과정에서 보안상의 심각한 문제가 발생할 수 있습니다.   
실제 사례로 '마누스'라는 AI에게 서버 내부 파일을 요청했더니, 스스로 자신의 기밀 자료를 찾아 제공하는 셀프 해킹 이슈가 발생했습니다. 기업이나 개인의 민감한 정보가 AI 에이전트를 통해 유출될 위험이 있습니다.

- **윤리적 문제**: AI 에이전트의 자율적 의사결정으로 인해 문제가 발생했을 때, 법적·윤리적 책임 소재를 명확히 가리기 어렵습니다.
- **비용과 속도**: 한 번의 답변을 위해 수십 번의 내부 추론과 도구 호출이 필요하여 비용이 많이 들고, 여러 개의 LLM 또는 SLM을 사용하기 때문에 상대적으로 속도가 느립니다.
</div>

<hr>

### 마치며
<div style="font-size: 18px;" markdown="1">
지금까지의 AI가 우리가 시키는 일만 잘하는 '똑똑한 도구'였다면, 미래의 AI 에이전트는 스스로 상황을 판단하고 해결책을 제시하는 **자율적인 주체**로 진화하고 있습니다. 앞으로 AI 에이전트는 단순히 성능이 좋아지는 것을 넘어, 다양한 형태로 우리 삶에 깊숙이 들어올 것으로 보입니다.

결국 미래의 AI 에이전트는 각 분야의 최고 전문가들이 모여 유기적으로 소통하고 협력하는 완벽한 팀을 이루는 모습이 될 것입니다. 단순한 챗봇을 넘어, 우리 곁에서 가장 복잡하고 난해한 문제들을 함께 해결해 나갈 AI 에이전트의 활약을 기대해 봅니다.
</div>


* * *
<span style="font-size: 20px;" markdown="1">**references** </span>
<div style="font-size: 14px;" markdown="1">
[2024 Google AI Agent Whitepaper]<https://www.kaggle.com/whitepaper-agents> <br>
[Google cloud - AI 에이전트]<https://cloud.google.com/discover/what-are-ai-agents?hl=ko#what-is-an-ai-agent> <br>
양승갑, [“AI 수동적 한계 넘으려면 ‘에이전트화’ 필요”]<https://www.dbpia.co.kr/Journal/articleDetail?nodeId=NODE12118995> <br>
KPMG, [AI 에이전트 혁신: 산업을 바꾸는 현재와 미래 전망]<https://kpmg.com/kr/ko/insights/eri/2025/issuemonitor_175.html> 
</div>
